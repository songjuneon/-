from re import A
import requests
from bs4 import BeautifulSoup
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}
 

search = input("검색할 키워드를 입력해주세요")

page = int(input("크롤링할 페이지(숫자)를 입력해주세요:"))

page_num =1
if page :
    page_num =(page-1)*10+1

url =url = "https://search.naver.com/search.naver?where=news&sm=tab_pge&query=" + search + "&start=" + str(page_num)

response = requests.get(url, headers = headers)
soup = BeautifulSoup(response.text, "html.parser")

articles =soup.select("div.group_news > ul.list_news >li div.news_area > a")
# print(articles)

print("네이버에 ", search, "를 검색했을 때의 뉴스 기사",end="\n")
print(page,"페이지의",end="") #end="" 는 띄어쓰기로 붙여짐
print(len(articles),"개의 기사가 검색됨", end= "\n\n")

article_file = open("article.txt","w", encoding="utf=8")


i= 1
for article in articles:
    print(str(i) + "번째 기사" +article.get_text(),"\n")
    article_file.write(str(i) + "번째 기사 : " +article.get_text()+"\n")
    i +=1
    

#함수나 모듈은 뛰어쓰기 안됨
#BeautifulSoup는 모듈명이 아님 기능명임
#리퀘스트 함수는 서버에 요청을 보내는 함수임
#print(response.text[:500]) 500자만 출력

#print(response.text)
#print(response.url)
#print(response.encoding) 데이터가 담긴 활당 번호를 알려주는 코드
#print(response.headers) html의 헤더의 정보를 가져오는 코드
#파싱은 우리가 가져온 문자열을 의미있는 데이터로 파서는 파이썬의 기본 도구

#print(soup.title)
#print(soup.title.string) 실제 제목값만 출력
#print(soup.span)
#print(soup.findAll('span'))
